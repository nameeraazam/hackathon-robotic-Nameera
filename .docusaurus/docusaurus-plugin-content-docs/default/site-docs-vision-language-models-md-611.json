{
  "id": "vision_language_models",
  "title": "Vision-Language Models (VLMs): Bridging the Digital Brain with the Physical World",
  "description": "This document explores Vision-Language Models (VLMs), a class of AI that combines the power of large language models with visual understanding. We will delve into their evolution, architecture, key capabilities, and provide a comparison of prominent models.",
  "source": "@site/docs/vision_language_models.md",
  "sourceDirName": ".",
  "slug": "/vision_language_models",
  "permalink": "/docs/vision_language_models",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/vision_language_models.md",
  "tags": [],
  "version": "current",
  "frontMatter": {},
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "AWS RoboMaker: Cloud-Based Robotics Development and Deployment",
    "permalink": "/docs/aws_robomaker"
  },
  "next": {
    "title": "Week 1-2 Assessment: Physical AI and Humanoid Fundamentals",
    "permalink": "/docs/week-01-02-physical-ai/assessment"
  }
}